I"*[<ul id="markdown-toc">
  <li><a href="#背景" id="markdown-toc-背景">背景</a>    <ul>
      <li><a href="#知识图谱概念" id="markdown-toc-知识图谱概念">知识图谱概念</a></li>
      <li><a href="#知识图谱结构" id="markdown-toc-知识图谱结构">知识图谱结构</a></li>
    </ul>
  </li>
  <li><a href="#其他术语" id="markdown-toc-其他术语">其他术语</a>    <ul>
      <li><a href="#语义网络" id="markdown-toc-语义网络">语义网络</a></li>
      <li><a href="#语义网和链接数据" id="markdown-toc-语义网和链接数据">语义网和链接数据</a></li>
    </ul>
  </li>
  <li><a href="#apache-jena" id="markdown-toc-apache-jena">Apache Jena</a>    <ul>
      <li><a href="#fuseki" id="markdown-toc-fuseki">Fuseki</a></li>
      <li><a href="#tdb" id="markdown-toc-tdb">TDB</a></li>
      <li><a href="#rdf" id="markdown-toc-rdf">RDF</a>        <ul>
          <li><a href="#d2rq" id="markdown-toc-d2rq">D2RQ</a></li>
        </ul>
      </li>
      <li><a href="#owl" id="markdown-toc-owl">OWL</a>        <ul>
          <li><a href="#推理引擎" id="markdown-toc-推理引擎">推理引擎</a></li>
        </ul>
      </li>
      <li><a href="#sparql" id="markdown-toc-sparql">SPARQL</a></li>
    </ul>
  </li>
  <li><a href="#环境搭建" id="markdown-toc-环境搭建">环境搭建</a></li>
  <li><a href="#开发者使用说明" id="markdown-toc-开发者使用说明">开发者使用说明</a>    <ul>
      <li><a href="#配置apache语义框架" id="markdown-toc-配置apache语义框架">配置apache语义框架</a></li>
      <li><a href="#向服务器上传数据" id="markdown-toc-向服务器上传数据">向服务器上传数据</a></li>
      <li><a href="#运行" id="markdown-toc-运行">运行</a></li>
    </ul>
  </li>
  <li><a href="#构建思路" id="markdown-toc-构建思路">构建思路</a>    <ul>
      <li><a href="#客户端构建" id="markdown-toc-客户端构建">客户端构建</a></li>
      <li><a href="#服务器端构建" id="markdown-toc-服务器端构建">服务器端构建</a></li>
      <li><a href="#搜索问题" id="markdown-toc-搜索问题">搜索问题</a>        <ul>
          <li><a href="#开放世界假定" id="markdown-toc-开放世界假定">开放世界假定</a></li>
        </ul>
      </li>
      <li><a href="#debug" id="markdown-toc-debug">debug</a></li>
    </ul>
  </li>
  <li><a href="#难点" id="markdown-toc-难点">难点</a></li>
  <li><a href="#kbqa" id="markdown-toc-kbqa">KBQA</a>    <ul>
      <li><a href="#知识库的类型" id="markdown-toc-知识库的类型">知识库的类型</a></li>
      <li><a href="#与对话系统对话机器人的交互式对话不同" id="markdown-toc-与对话系统对话机器人的交互式对话不同">与对话系统、对话机器人的交互式对话不同</a></li>
      <li><a href="#知识库问答的主流方法" id="markdown-toc-知识库问答的主流方法">知识库问答的主流方法</a></li>
    </ul>
  </li>
  <li><a href="#研究方向" id="markdown-toc-研究方向">研究方向</a></li>
  <li><a href="#思维" id="markdown-toc-思维">思维</a>    <ul>
      <li><a href="#大局观" id="markdown-toc-大局观">大局观</a></li>
      <li><a href="#知识的流动形式" id="markdown-toc-知识的流动形式">知识的流动形式</a></li>
      <li><a href="#机器学习" id="markdown-toc-机器学习">机器学习</a></li>
    </ul>
  </li>
</ul>

<h1 id="背景">背景</h1>

<p>Google知识图谱的宣传语“things not strings”</p>

<h3 id="知识图谱概念">知识图谱概念</h3>
<ul>
  <li>实现Web从<strong>网页链接向概念链接转变</strong>，支持用户按主题而不是字符串检索，从而实现真正的语义检索</li>
  <li>基于知识图谱的搜索引擎，能够以<strong>图形方式</strong>向用户反馈<strong>结构化</strong>的知识，用户不必浏览大量网页，就可以准确定位和深度获取知识</li>
  <li>知识图谱作为人工智能领域的关键技术，是一种智能、高效的<strong>组织、管理和利用海量信息的方式</strong>. 目前知识图谱已广泛应用于智能语义搜索、移动个人助理、以及深度问答系统。</li>
  <li>知识图谱的构建涉及<strong>知识建模、关系抽取、图存储、关系推理、实体融合</strong>等多方面的技术，而知识图谱的应用则涉及到语义搜索、智能问答、语言理解、决策分析等多个领域</li>
</ul>

<h3 id="知识图谱结构">知识图谱结构</h3>
<ul>
  <li>Schema层. 知识图谱是由本体（Ontology）作为Schema层，和RDF数据模型兼容的结构化数据集</li>
  <li>SPO. 知识图谱是由一些相互连接的实体和他们的属性构成的。换句话说，知识图谱是由一条条知识组成，每条知识表示为一个SPO三元组(Subject-Predicate-Object)。</li>
  <li>两种节点类型. 资源和字面量。借用数据结构中树的概念，字面量类似叶子节点，出度为0</li>
</ul>

<p>本项目需要对获取到的领域数据进行实体识别和关系抽取。并在统一的术语下，将知识融合成知识库，并从已有的知识数据中获取隐含知识，预测实体间隐含的关系，进而实现知识图谱的自动补全完善。</p>

<p>知识图谱数据的来源主要有三个：<strong>结构化数据、半结构化数据和非结构化</strong>的数据。我们所使用的电影数据就是结构化的数据。半结构化的数据指的是数据有一定的组织形式，但较结构化数据而言更松散（属性名和属性值具有多样性，比如“生日”就有“出生日期”、“诞辰”等多种表达方式）</p>

<h1 id="其他术语">其他术语</h1>
<h3 id="语义网络">语义网络</h3>
<p>在表现形式上，语义网络和知识图谱相似，但语义网络更侧重于描述概念与概念之间的关系，（有点像生物的层次分类体系——界门纲目科属种），而知识图谱则更偏重于描述实体之间的关联</p>

<h3 id="语义网和链接数据">语义网和链接数据</h3>
<p>相对于语义网络，语义网和链接数据倾向于描述万维网中资源、数据之间的关系。其实，本质上，语义网、链接数据还有Web 3.0都是同一个概念，只是在不同的时间节点和环境中，它们各自描述的角度不同。它们都是指W3C制定的用于描述和关联万维网数据的一系列技术标准，即，语义网技术栈。</p>

<p>语义网正是为了使得网络上的数据变得机器可读而提出的一个通用框架。“Semantic”就是用更丰富的方式来表达数据背后的含义，让机器能够理解数据。“Web”则是希望这些数据相互链接，组成一个庞大的信息网络，正如互联网中相互链接的网页，只不过基本单位变为粒度更小的数据</p>

<p>语义网络指Semantic Network，语义网指Semantic Web。</p>

<h1 id="apache-jena">Apache Jena</h1>
<p>Apache Jena（后文简称Jena），是一个开源的Java语义网框架（open source Semantic Web Framework for Java），用于构建语义网和链接数据应用。</p>

<p>RDF，OWL和SPARQL称为语义网的三大核心技术</p>
<h3 id="fuseki">Fuseki</h3>
<p>Fuseki是Jena提供的SPARQL服务器，也就是SPARQL endpoint。其提供了四种运行模式：单机运行、作为系统的一个服务运行、作为web应用运行或者作为一个嵌入式服务器运行</p>
<h3 id="tdb">TDB</h3>
<p>TDB是Jena用于存储RDF的组件，是属于存储层面的技术。在单机情况下，它能够提供非常高的RDF存储性能。目前TDB的最新版本是TDB2，且与TDB1不兼容。</p>

<p>商品图谱数据在百亿级，图数据库存储开销很大。为了保证毫秒级响应和成本控制的考量，阿里的研究团队采用了分级存储的架构</p>
<h3 id="rdf">RDF</h3>
<p>Jena提供了RDFS、OWL和通用规则推理机。其实Jena的RDFS和OWL推理机也是通过Jena自身的通用规则推理机实现的。</p>

<p>.ttl是Turtle 格式的简称，是RDF数据的表达格式之一。RDF是一种数据模型，表达出来时候需要一种表达格式，就是所谓的serialization。最初的的格式是xml/rdf格式，但是过于繁琐，turtle则直观简单很多。turtle文件一般可以被语义网软件包解读，比如Jena就可以解读turtle文件。</p>

<p>RDF(Resource Description Framework)，即资源描述框架，其本质是一个数据模型（Data Model）。它提供了一个统一的标准，用于描述实体/资源。简单来说，就是表示事物的一种方法和手段。RDF形式上表示为SPO三元组，有时候也称为一条语句（statement），知识图谱中我们也称其为一条知识</p>

<p>RDF序列化的方式主要有：RDF/XML，N-Triples，Turtle，RDFa，JSON-LD等几种</p>

<p>RDF的提出解决了语义网络的部分缺点，在节点和边的取值上做了约束，制定了统一标准，为多源数据的融合提供了便利</p>

<blockquote>
  <p>rdf:type &lt;==&gt; a &lt;==&gt; is-a
这种引入Unicode字符的资源标识符称为国际化资源标识符（IRI）。是URI的扩展</p>
</blockquote>

<h5 id="d2rq">D2RQ</h5>
<blockquote>
  <ul>
    <li>D2RQ是隐式将SPARQL语句对RDF的操作变换到SQL上</li>
    <li>jena是直接把RDF数据上传到网络上
用D2RQ转换MySQL为RDF数据. 即.ttl文件和.nt文件</li>
  </ul>
</blockquote>

<p>换个说法，D2RQ把SPARQL查询，按照mapping文件，翻译成SQL语句完成最终的查询，然后把结果返回给用户</p>

<p>D2RQ是以虚拟RDF图的方式来访问关系数据库，在访问频率不高，数据变动频繁的场景下，这种方式比较合适。</p>

<p>对于访问频率比较高的场景（比如KBQA），将数据转为RDF再提供服务更为合适。利用Apache Jena，创建基于显式RDF数据的SPARQL endpoint</p>

<p>p.s. D2RQ是RDB==&gt;RDF的一种方式，RDB==&gt;RDF有两个标准（还可以选择direct-mapping），经过 D2RQ处理后，仍然需要人工根据本体文件，进行修改，得到最终的RDF文件</p>

<h3 id="owl">OWL</h3>
<p>使用protege建立owl文件，也就是所谓的本体文件，确定数据与数据之间的关系</p>

<p>RDFS和OWL这两种技术或者说模式语言/本体语言（schema/ontology language）解决了RDF表达能力有限的困境. 引入了类和对象的概念以及泛化抽象能力</p>
<blockquote>
  <p>rdf/rdfs/owl都有自己预定义的词汇</p>
</blockquote>

<p>用过Mysql的读者应该知道，其database也被称作schema。这个schema和我们这里提到的schema language十分类似。我们可以认为数据库中的每一张表都是一个类（Class）</p>

<p>OWL，即“Web Ontology Language”，语义网技术栈的核心之一。OWL有两个主要的功能：</p>
<ol>
  <li>提供快速、灵活的数据建模能力。</li>
  <li>高效的自动推理</li>
</ol>

<h5 id="推理引擎">推理引擎</h5>
<p>一级翻译器：将自然语言转换成逻辑语言（规则/神经网络模型）
推理单元：基于知识图谱逻辑展开
二级翻译器：逻辑语言转为数据库语言</p>

<p>owl区分数据属性和对象属性（对象属性表示实体和实体之间的关系）,数据属性表示实体的属性
owl有本体映射词汇,即类等价或属性等价等,用于知识融合</p>

<p>知识图谱的推理主要分为两类：基于本体的推理和基于规则的推理</p>

<p>本体的构建.
自顶向下:特定领域.精准,目前的语音助手用
自下而上:开放域</p>

<h3 id="sparql">SPARQL</h3>
<p>两个部分组成：协议和查询语言。</p>
<ul>
  <li>查询语言很好理解，就像SQL用于查询关系数据库中的数据，XQuery用于查询XML数据，SPARQL用于查询RDF数据。</li>
  <li>协议是指我们可以通过HTTP协议在客户端和SPARQL服务器（SPARQL endpoint）之间传输查询和结果，这也是和其他查询语言最大的区别。</li>
</ul>

<h1 id="环境搭建">环境搭建</h1>
<p>linux, python27, jdk8
apache jena fuseki
python工具包:jieba，REFO，SPARQLWrapper</p>

<h1 id="开发者使用说明">开发者使用说明</h1>
<h3 id="配置apache语义框架">配置apache语义框架</h3>
<p>cd apache-jena-fuseki-3.10.0 
./fuseki-server –config fuseki_conf.ttl</p>
<h3 id="向服务器上传数据">向服务器上传数据</h3>
<p>http://localhost:3030
选择项目下的kg_demo_movie.nt，作为默认数据集upload</p>
<h3 id="运行">运行</h3>
<p>source activate python27	# 进入虚拟环境
python query_main.py	# 执行KB_query目录下的query_main.py文件。
输入查询: 周润发演了那些电影？
得到结果: …</p>

<blockquote>
  <p>一个终端运行服务器,可以实时查看log
第二个终端运行python程序,进行查询</p>
</blockquote>

<h1 id="构建思路">构建思路</h1>
<h3 id="客户端构建">客户端构建</h3>
<p>基于 REfO 的 KBQA 实现及示例
这是一个基于 Python 模块 REfO 实现的知识库问答初级系统. 该问答系统可以解析输入的自然语言问句生成 SPARQL 查询，进一步请求后台基于 TDB 知识库的 Apache Jena Fuseki 服务, 得到结果.
不同的表述能够用统一的”对象正则表达式”匹配得到结果, 进而生成对应 SPARQL 查询语句.</p>

<ol>
  <li>jieba对自然语言分词/命名实体识别. 引入外部词典(电影/人名)
    <ul>
      <li>
        <p>学术上NER所涉及的命名实体一般包括3大类（实体类，时间类，数字类）和7小类（人名、地名、组织机构名、时间、日期、货币、百分比）。</p>
      </li>
      <li>
        <p>实际应用中，NER模型通常只要识别出人名、地名、组织机构名、日期时间即可.只要是业务需要的特殊文本片段都可以称为实体。</p>
      </li>
    </ul>
  </li>
  <li>使用正则表达式的方式来解析自然语言</li>
  <li>REFO对处理后的语句进行对象封装
    <ul>
      <li>利用REfo模块对词进行对象级别(object-level)的正则匹配．</li>
      <li>不同的表述能够用统一的”对象正则表达式”匹配得到结果</li>
    </ul>
  </li>
  <li>SPARQLWrapper将语句对象变为sparql查询语句, 并向服务器提交请求.</li>
  <li>请求后台基于 TDB 知识库的 Apache Jena Fuseki 服务, 得到结果．
    <ul>
      <li>服务器搭建了jena框架,经过d2qr变换. 把sparql语句对RDF的查询,转变为mysql对表的查询</li>
    </ul>
  </li>
</ol>

<h3 id="服务器端构建">服务器端构建</h3>

<ol>
  <li>爬虫爬取结构化数据, 插入mysql数据库</li>
  <li>利用proteus, 建立owl文件,抽象出类,设立推理规则/rule.ttl</li>
  <li>d2qr建立map.ttl/kg.ttl, 将表数据转换为RDF格式的数据</li>
  <li>根据类,对rdf数据进行修改.</li>
  <li>利用jena框架, 配置fuseki_conf.ttl, 引用owl.ttl文件,传rdf数据,提供sparql查询环境</li>
</ol>

<h3 id="搜索问题">搜索问题</h3>
<ul>
  <li>演员的介绍/可细节询问生日等</li>
  <li>电影的介绍/可细节询问发行日期等</li>
  <li>演员的电影</li>
  <li>某电影的演员</li>
  <li>几个演员合作的电影</li>
  <li>某演员评分在某范围的电影</li>
  <li>某演员演过哪些类型的电影</li>
  <li>演员的某类型的电影</li>
  <li>某演员一共演了多少电影</li>
  <li>某演员是喜剧演员吗
    <h5 id="开放世界假定">开放世界假定</h5>
    <p>Open-world assumption，OWA。这个假定的意思是当前没有陈述的事情是未知的，或者说知识图谱没有包含的信息是未知的</p>
  </li>
</ul>

<p>回复有:</p>
<ul>
  <li>i donnot know	# 表示查询结果为空, 未知</li>
  <li>i donnot understand	# 表示输入格式非机器可理解</li>
</ul>

<h3 id="debug">debug</h3>
<p>若出现端口占用
lsof -i:3030
kill -9 port_num</p>

<h1 id="难点">难点</h1>

<ol>
  <li>数据支持层-存储数据的方式
    <ol>
      <li>jena+mysql. 使用语义描述语言OWL对知识库进行描述,通过预先定义好的推理函数进行推理</li>
      <li>neo4j图数据库.使用图结构来描述整个知识库,推理即对图中节点进行遍历</li>
    </ol>
  </li>
  <li>知识融合层
    <ol>
      <li>SPO三元组抽取
        <ul>
          <li>从结构化数据库中获取知识：D2R
 难点：复杂表数据的处理</li>
          <li>从链接数据中获取知识：图映射
 难点：数据对齐</li>
          <li>从半结构化（网站）数据中获取知识：使用包装器
 难点：方便的包装器定义方法，包装器自动生成、更新与维护</li>
          <li>从文本中获取知识：信息抽取
 难点：结果的准确率与覆盖率</li>
        </ul>
      </li>
    </ol>

    <p>纯文本数据会涉及到的实体识别、实体链接、实体关系识别、概念抽取 等，需要用到许多自然语言处理的技术，包括但不仅限于分词、词性标注、分布式语义表达、篇章潜在主题分析、同义词构建、语义解析、依存句法、语义角色标注、语义相似度计算等等</p>
    <ol>
      <li>融合
 将不同数据源获取的知识进行融合构建数据之间的关联。包括实体对齐、属性对齐、冲突消解、规范化等，这一部分很多都是 dirty work，更多的是做一个数据的映射、实体的匹配，可能还会涉及的是本体的构建和融合。最后融合而成的知识库存入上一部分提到的数据库中。如有必要，也需要如 Spark 等大数据平台提供高性能计算能力，支持快速运算</li>
    </ol>
  </li>
  <li>知识验证
分为补全、纠错、外链、更新各部分，确保知识图谱的一致性和准确性</li>
  <li>知识计算和应用
知识计算主要是根据图谱提供的信息得到更多隐含的知识，像是通过本体或者规则推理技术可以获取数据中存在的隐含知识；通过链接预测预测实体间隐含的关系；通过社区计算在知识网络上计算获取知识图谱上存在的社区，提供知识间关联的路径……通过知识计算知识图谱可以产生大量的智能应用如专家系统、推荐系统、语义搜索、问答等。</li>
</ol>

<blockquote>
  <p>构建步骤: 数据获取 ==&gt; 数据存储 ==&gt; 数据可视化</p>
</blockquote>

<h1 id="kbqa">KBQA</h1>
<p><a href="https://zhuanlan.zhihu.com/p/25735572">知乎专栏</a>
知识库问答（knowledge base question answering, KB-QA）.即给定自然语言问题，通过对问题进行语义理解和解析，进而利用知识库进行查询、推理得出答案</p>
<h3 id="知识库的类型">知识库的类型</h3>
<ul>
  <li>Gurated KBs, 结构化的wiki;</li>
  <li>Extracted KBs, 直接从网页中抽取三元组. 精确度低
    <ul>
      <li>实体链指: 文档中的实体名字==&gt;知识库中的实体.实体识别和实体消歧</li>
      <li>关系抽取: 词性标注(POS), 语法分析, 关系分类</li>
    </ul>
  </li>
</ul>

<h3 id="与对话系统对话机器人的交互式对话不同">与对话系统、对话机器人的交互式对话不同</h3>
<p>KB-QA具有以下特点：</p>
<ol>
  <li>答案：回答的答案是知识库中的实体或实体关系，或者no-answer（即该问题在KB中找不到答案），当然这里答案不一定唯一，比如 中国的城市有哪些 。而对话系统则回复的是自然语言句子，有时甚至需要考虑上下文语境。</li>
  <li>评价标准：回召率 (Recall)，精确率 (Precision) ，F1-Score。而对话系统的评价标准以人工评价为主，以及BLEU和Perplexity。</li>
</ol>

<h3 id="知识库问答的主流方法">知识库问答的主流方法</h3>
<ol>
  <li>语义解析. 可以通过查询语句直接在知识库中查询最终答案.涉及到较多的linguistic和手工规则</li>
  <li>信息抽取. 根据实体得到子图和候选答案.观察问题依据规则进行信息抽取,得到问题的特征向量,对候选答案进行筛选,得到最终答案</li>
  <li>向量建模.类似信息抽取. 黑盒,缺少解释性.缺少先验知识和推理.无需任何手工定义的特征</li>
  <li>深度学习方法: CNN/LSTM</li>
</ol>

<p>词汇表即自然语言与知识库实体或知识库实体关系的单点映射，构建词汇表也被称为对齐（Alignment）.方法: 字符串匹配或者基于统计(文档中和知识库中的统计结果相似)</p>

<h1 id="研究方向">研究方向</h1>
<p>1.实体识别。
现状：通过人工预定义的实体类型和实体关系类型进行实体抽取和关系抽取
改进：如何通过机器学习对实体边界进行识别，实现更高质量的实体分类，从而提高实体识别的准确率和召回率。运用机器学习方法，代替人工
2.关系抽取。
如何利用语料中的关系词汇对实体关系进行建模，自动构造高质量实体关系训练集。规则的设立，　代替正则表达式
3.实体对齐。
知识融合．如何有效的进行实体对齐，构建准确、高效的知识图谱系统。</p>

<h1 id="思维">思维</h1>

<h3 id="大局观">大局观</h3>
<p>先问为什么需要,</p>

<p>然后考虑实现方式和解决方案.</p>

<p>综合比较各种方案</p>

<h3 id="知识的流动形式">知识的流动形式</h3>
<p>文字/语音/图片/影像, 应该可以相互转换,本质是一种意识,即数据流/信息流,web</p>

<p>结构化. we can fake everything</p>

<p>机器和生物的结合</p>

<h3 id="机器学习">机器学习</h3>
<p>为了让机器能够理解文本背后的含义，我们需要对可描述的事物(实体)进行建模，填充它的属性，拓展它和其他事物的联系，即，构建机器的先验知识。</p>

<p>机器学习界有三个主要学派，符号主义（Symbolicism）、连接主义（Connectionism）、行为主义（Actionism）</p>

<p>大数据与机器学习等技术的快速发展使大规模人类知识体系的自动构建成为现实</p>

<p>人工智能的技术瓶颈不是要代替智人作为动物的那一部分感知智能，而在于代替我们最近几千年发展起来的那些认知能力，也就是我们有了符号思维能力之后的智能。</p>

<p>我们回过头来看，向工程妥协的时候，我们就胜利。向教条主义坚持的时候，我们就失败。就是整个领域的总结吧。2006年之前的时候，我们由弱语义转向强语义，我们就失败了，因为我们看重的是科学。2006年的时候，我们看重的是工程，所以就取得了小小的成功。</p>

<p>往前走的话，我觉得我们做工程，不是某一个领域，某一个算法就能解决的。比如我们现在构造知识图谱，需要知识工程的技术，需要自然语言处理的技术，需要规则系统，需要正则表达式，有时候可能正则表达式是最重要的。各种low的、high tech的东西。我们今天在写正则表达式，明天就在玩词嵌入。各种有机的算法我们都要融合在一起。没有什么人工智能技术是高的或者低的，一定是有效的才是最好的。</p>

:ET